{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install swarmauri[full]==0.4.0\n",
    "import os\n",
    "import gradio as gr\n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from swarmauri.standard.llms.concrete.GroqModel import GroqModel\n",
    "from swarmauri.standard.agents.concrete.SimpleConversationAgent import SimpleConversationAgent\n",
    "from swarmauri.standard.conversations.concrete.Conversation import Conversation\n",
    "\n",
    "# Set the API key directly (for testing purposes; not recommended for production)\n",
    "API_KEY = \"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\"\n",
    "\n",
    "# Initialize the GroqModel with the provided API key\n",
    "llm = GroqModel(api_key=API_KEY)\n",
    "\n",
    "# Create a SimpleConversationAgent with the GroqModel\n",
    "agent = SimpleConversationAgent(llm=llm, conversation=Conversation())\n",
    "\n",
    "# Define the function to handle both text and audio input\n",
    "def converse(history, input_text, audio_file):\n",
    "    if audio_file is not None:\n",
    "        # Handle audio input - Pre-process and convert audio file to text\n",
    "        audio = AudioSegment.from_file(audio_file)\n",
    "        # Convert to mono channel\n",
    "        audio = audio.set_channels(1)\n",
    "        # Normalize volume\n",
    "        audio = audio.normalize()\n",
    "        # Export the preprocessed audio to a new file\n",
    "        audio.export(\"processed_audio.wav\", format=\"wav\")\n",
    "\n",
    "        # Use the speech recognition library to transcribe the audio\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(\"processed_audio.wav\") as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "            try:\n",
    "                input_text = recognizer.recognize_google(audio_data)\n",
    "            except sr.UnknownValueError:\n",
    "                history.append((\"Audio Input\", \"Sorry, I could not understand the audio.\"))\n",
    "                return history\n",
    "            except sr.RequestError:\n",
    "                history.append((\"Audio Input\", \"Sorry, there was an issue with the speech recognition service.\"))\n",
    "                return history\n",
    "    elif input_text:\n",
    "        # If text input is provided, use it directly\n",
    "        input_text = input_text\n",
    "    else:\n",
    "        history.append((\"\", \"Please provide either a text input or an audio file.\"))\n",
    "        return history\n",
    "\n",
    "    # Process the input text through the conversation agent\n",
    "    result = agent.exec(input_text)\n",
    "    history.append((input_text, result))\n",
    "    return history\n",
    "\n",
    "# Function to reset inputs and conversation history\n",
    "def reset_all():\n",
    "    return [], gr.update(value=\"\"), gr.update(value=None)\n",
    "\n",
    "# Customize the Gradio interface with both text and audio inputs\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"<h1 style='text-align: center; color: #4A90E2;'>ðŸ¤– Ask Me Anything!</h1>\")\n",
    "    gr.Markdown(\"<p style='text-align: center; font-size: 1.2em;'>Type your message or upload an audio file, and I'll do my best to assist you!</p>\")\n",
    "\n",
    "    # Set initial height for the chatbot\n",
    "    chatbot = gr.Chatbot(label=\"Conversation\", height=200)  # Initial height set to 200 pixels\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=7):\n",
    "            text_input = gr.Textbox(label=\"Your Message\", placeholder=\"Type your message here...\", show_label=True)\n",
    "        with gr.Column(scale=3):\n",
    "            upload_button = gr.Audio(type=\"filepath\", label=\"Or Upload Audio\", interactive=True)\n",
    "\n",
    "    submit_button = gr.Button(\"Submit\", variant=\"primary\")\n",
    "    reset_button = gr.Button(\"Reset\")\n",
    "\n",
    "    # Link the function to the inputs and outputs\n",
    "    submit_button.click(converse, inputs=[chatbot, text_input, upload_button], outputs=chatbot)\n",
    "    submit_button.click(reset_all, outputs=[chatbot, text_input, upload_button])  # Reset inputs after submission\n",
    "\n",
    "    # Enable \"Enter\" key to trigger the submit action\n",
    "    text_input.submit(converse, inputs=[chatbot, text_input, upload_button], outputs=chatbot)\n",
    "    text_input.submit(reset_all, outputs=[chatbot, text_input, upload_button])  # Reset inputs after submission\n",
    "\n",
    "    reset_button.click(fn=reset_all, outputs=[chatbot, text_input, upload_button])  # Reset everything\n",
    "\n",
    "# Launch the Gradio interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
